# v0.dev - AI Chat Generative UI

**v0.dev** is a modern, full-stack, AI-powered chat UI application designed for developers who want seamless integration with powerful LLM providers like **Together AI** and **Groq**. Built with **Next.js**, **TypeScript**, and **Tailwind CSS**, it delivers real-time, responsive chat capabilities with a beautiful and intuitive interface.

---

## ğŸš€ Features

* ğŸ§  **LLM Switching** â€” Toggle between Together AI and Groq models on the fly
* ğŸ’¬ **Real-Time Chat** â€” Sleek, reactive message handling and history
* ğŸ¨ **Modern Design** â€” Built with shadcn/ui + Tailwind CSS for ultimate theming
* ğŸ§© **Component-Driven** â€” Modular, reusable code structure
* ğŸŒ **Multilingual Support** â€” Smart response localization matching user input
* ğŸ§  **Chain of Thought (CoT)** â€” Enhanced reasoning before responding using XML-style encapsulation
* ğŸ“± **Responsive Layout** â€” Fully optimized for mobile, tablet, and desktop
* ğŸ› ï¸ **Type-Safe** â€” Leveraging TypeScript for strong developer confidence
* ğŸŒˆ **Enhanced Markdown & MDX** â€” Rich, dynamic documentation support with special components

---

## ğŸ§° Tech Stack

* **Next.js 14 (App Router)**
* **TypeScript**
* **Tailwind CSS + shadcn/ui**
* **Together AI SDK**
* **Groq API SDK**

---

## ğŸ“¦ Getting Started

### Prerequisites

* Node.js 18+
* npm or yarn
* API keys from [Together AI](https://together.ai) and [Groq](https://console.groq.com)

### Installation

```bash
git clone https://github.com/likhonsdev/v0.dev.git
cd v0.dev
npm install  # or yarn install
```

### Environment Variables

Create a `.env` file:

```env
TOGETHER_API_KEY=your-together-api-key
GROQ_API_KEY=your-groq-api-key
```

### Run Dev Server

```bash
npm run dev
# or
yarn dev
```

Now open [http://localhost:3000](http://localhost:3000) in your browser.

---

## ğŸ“ Project Structure

```
v0.dev/
â”œâ”€â”€ app/                  # Next.js pages & routing
â”‚   â”œâ”€â”€ chat/             # Chat UI & server logic
â”‚   â”œâ”€â”€ components/       # Page-level components
â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â””â”€â”€ lib/              # Local utilities
â”œâ”€â”€ components/           # Shared UI elements
â”‚   â””â”€â”€ ui/               # shadcn/ui components
â”œâ”€â”€ lib/                  # Global utility functions
â”œâ”€â”€ public/               # Static assets (images, icons)
â””â”€â”€ styles/               # Tailwind and custom CSS
```

---

## ğŸ¤– Supported Models

### Together AI

* Llama 3.1 8B (Free Tier)
* Llama 3.1 70B
* Mixtral 8x7B
* DeepSeek Coder 33B

### Groq

* Llama 3 8B
* Llama 3 70B
* Mixtral 8x7B
* Gemma 7B

---

## ğŸŒ Deployment

Deploy with a single click on Vercel:

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flikhonsdev%2Fv0.dev)

> Ensure your environment variables are set on Vercel for seamless API communication.

---

## ğŸ§  MDX Features

Leverage extended MDX syntax and custom components:

* `<LinearProcessFlow />` â€“ Ideal for visual walkthroughs
* `<Quiz />` â€“ Interactive learning/testing
* `<math>` â€“ Inline LaTeX-style math rendering
* `<Thinking />` â€“ Encapsulates internal reasoning before output

### Code Block Enhancements

````tsx
```tsx project="v0.dev" file="components/Chat.tsx" type="react"
```
````

Other formats:

* `nodejs`, `html`, `markdown`, `mermaid`, `python`, etc.

---

## ğŸ§ª Advanced Techniques

* **Chain of Thought Reasoning (CoT)**: System processes logic before generating response.
* **Prompt Meta-Tagging**: Enhanced control over rendering & output.
* **Multimodal Input-Awareness**: Supports complex structured queries.

---

## ğŸ¤ Contributing

We welcome PRs! Fork the repo, create a feature branch, and submit your changes.

---

## ğŸ“„ License

Licensed under the **MIT License**.

---

## ğŸ¯ Roadmap Ideas

* ğŸ”Œ Plugin system for model extensions
* ğŸ“Š Analytics dashboard for token usage
* ğŸ—£ï¸ Voice input/output support
* ğŸ§  Multi-turn memory & RAG
